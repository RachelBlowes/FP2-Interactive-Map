{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from zipfile import ZipFile\n",
    "from shapely.geometry import mapping\n",
    "from datetime import datetime\n",
    "from functools import reduce\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dp/6l162bjn4pzdgpn5hkysn1dr0000gn/T/ipykernel_73756/1451209639.py:2: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  permits = pd.read_csv('raw/Boston Approved Building Permits 2009-2022.csv')\n",
      "/var/folders/dp/6l162bjn4pzdgpn5hkysn1dr0000gn/T/ipykernel_73756/1451209639.py:3: DtypeWarning: Columns (8,9,24,25,26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  SAM = pd.read_csv('raw/Live_Street_Address_Management_(SAM)_Addresses.csv')\n"
     ]
    }
   ],
   "source": [
    "sales = pd.read_csv('raw/boston_residential_sales.csv')\n",
    "permits = pd.read_csv('raw/Boston Approved Building Permits 2009-2022.csv')\n",
    "SAM = pd.read_csv('raw/Live_Street_Address_Management_(SAM)_Addresses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean sales and add parcels to it - include all data, just add parcels from the SAM\n",
    "SAM.rename(columns={'X': 'lon', 'Y': 'lat', 'PARCEL': 'parcel_id'}, inplace=True)\n",
    "SAM_processed = SAM[['FULL_ADDRESS', 'parcel_id', 'MAILING_NEIGHBORHOOD', 'ZIP_CODE']]\n",
    "SAM_processed = SAM_processed.groupby('FULL_ADDRESS').agg({'MAILING_NEIGHBORHOOD': 'first', 'parcel_id': 'first', 'ZIP_CODE': 'first'}).reset_index()\n",
    "sales_parcels = pd.merge(sales, SAM_processed, left_on=['address'], right_on = ['FULL_ADDRESS'], how='left')\n",
    "sales_parcels['date'] = pd.to_datetime(sales_parcels['date']).dt.date\n",
    "sales_parcels = sales_parcels.sort_values(by=['parcel_id', 'date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dollar_to_float(currency_str):\n",
    "    # Remove dollar signs and commas, then convert to float\n",
    "    return float(currency_str.replace('$', '').replace(',', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean permits\n",
    "permits['issued_date'] = pd.to_datetime(permits['issued_date']).dt.date\n",
    "residential_occupancy = ['1-3FAM', '6Unit', '1-2FAM', '1Unit', 'Mixed',\n",
    "       '7More', '1-4FAM', 'Multi', '2unit', '1-7FAM',\n",
    "       '7unit', '3unit', 'VacLd', '6unit', '4unit', '5unit', 'MIXED', '4Unit']\n",
    "permits = permits[(permits['occupancytype'].isin(residential_occupancy)) | (pd.isna(permits['occupancytype']))]\n",
    "permits.reset_index(drop=True, inplace=True)\n",
    "permits = permits[['worktype','permittypedescr', 'description', 'comments', 'declared_valuation', 'total_fees', 'issued_date', 'owner','owner type','occupancytype','parcel_id']]\n",
    "# Values to remove\n",
    "values_to_remove_valu = ['($40,000.00)', '($200,000.00)']\n",
    "# Create a mask for rows to drop\n",
    "mask_valu_drop = permits['declared_valuation'].isin(values_to_remove_valu)\n",
    "# Drop these rows\n",
    "permits = permits.drop(permits[mask_valu_drop].index)\n",
    "permits['declared_valuation'] = permits['declared_valuation'].apply(convert_dollar_to_float)\n",
    "permits['total_fees'] = permits['total_fees'].apply(convert_dollar_to_float)\n",
    "\n",
    "permits_process = permits.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "worktype               object\n",
       "permittypedescr        object\n",
       "description            object\n",
       "comments               object\n",
       "declared_valuation    float64\n",
       "total_fees            float64\n",
       "issued_date            object\n",
       "owner                  object\n",
       "owner type             object\n",
       "occupancytype          object\n",
       "parcel_id             float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permits.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define new df and initialize columns\n",
    "sales_with_permits_by_date = sales_parcels.copy()\n",
    "sales_with_permits_by_date['permit_valu_up2_sale'] = pd.Series([np.nan] * len(sales_with_permits_by_date))\n",
    "sales_with_permits_by_date['permit_fees_up2_sale'] = pd.Series([np.nan] * len(sales_with_permits_by_date))\n",
    "sales_with_permits_by_date['investor_permit'] = None\n",
    "sales_with_permits_by_date['investor_type_permit'] = None\n",
    "sales_with_permits_by_date['comments'] = None\n",
    "sales_with_permits_by_date['description'] = None\n",
    "sales_with_permits_by_date['permittypedescr'] = None\n",
    "sales_with_permits_by_date['worktype'] = None\n",
    "sales_with_permits_by_date['occupancy_permit'] = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sale = sales_with_permits_by_date.iloc[9]\n",
    "# mask = (permits_process['parcel_id'] == sale['parcel_id']) & (permits_process['issued_date'] < sale['date'])\n",
    "\n",
    "# relevant_permits = permits_process[mask]\n",
    "# print(sale['parcel_id'])\n",
    "# print(sale['date'])\n",
    "# print(sale)\n",
    "# print(relevant_permits['issued_date'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_permits(sales_df, permits_df):\n",
    "\n",
    "    sales_df = sales_df.sort_values(by=['parcel_id', 'date'])\n",
    "\n",
    "    # Process each transaction\n",
    "    for idx, sale in sales_df.iterrows():\n",
    "        # Filter permits based on 'parcel_id' and dates prior to the sale date\n",
    "        mask = (permits_df['parcel_id'] == sale['parcel_id']) & (permits_df['issued_date'] < sale['date'])\n",
    "        relevant_permits = permits_df[mask]\n",
    "        \n",
    "        # Summarize 'declared_valuation' and 'total_fees'\n",
    "        if not relevant_permits.empty:\n",
    "            sales_df.at[idx, 'permit_valu_up2_sale'] = relevant_permits['declared_valuation'].sum()\n",
    "            sales_df.at[idx, 'permit_fees_up2_sale'] = relevant_permits['total_fees'].sum()\n",
    "            \n",
    "            # Find the owner with the largest declared valuation\n",
    "            largest_valuation_row = relevant_permits.loc[relevant_permits['declared_valuation'].idxmax()]\n",
    "\n",
    "            # Get the owner and owner type from the largest valuation row\n",
    "            sales_df.at[idx, 'investor_permit'] = largest_valuation_row['owner']\n",
    "            sales_df.at[idx, 'investor_type_permit'] = largest_valuation_row['owner type']\n",
    "            sales_df.at[idx, 'occupancy_permit'] = largest_valuation_row['occupancytype']\n",
    "            \n",
    "            # Concatenate and set the fields from all relevant_permits\n",
    "            sales_df.at[idx, 'comments'] = '|'.join(relevant_permits['comments'].dropna().astype(str))\n",
    "            sales_df.at[idx, 'description'] = ','.join(relevant_permits['description'].dropna().astype(str))\n",
    "            sales_df.at[idx, 'permittypedescr'] = ','.join(relevant_permits['permittypedescr'].dropna().astype(str))\n",
    "            sales_df.at[idx, 'worktype'] = ','.join(relevant_permits['worktype'].dropna().astype(str))\n",
    "\n",
    "            # Remove processed permits from the permits_df\n",
    "            permits_df = permits_df.drop(relevant_permits.index)\n",
    "\n",
    "    return sales_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_sales_with_permits_by_date = process_permits(sales_with_permits_by_date, permits_process)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9363216985326812"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_sales_with_permits_by_date.to_csv('/Users/adi/Dropbox (MIT)/6.C35 Group Project/Data/Modified Datasets/Adi/sales_permitsData_by_date_nullincl.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dp/6l162bjn4pzdgpn5hkysn1dr0000gn/T/ipykernel_67543/224187964.py:2: DtypeWarning: Columns (67,68,69,73,74,75,76,77,78,79) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  updated_sales_with_permits_by_date = pd.read_csv('output/sales_permitsData_by_date_nullincl.csv')\n",
      "/var/folders/dp/6l162bjn4pzdgpn5hkysn1dr0000gn/T/ipykernel_67543/224187964.py:3: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  all_permits = pd.read_csv('raw/Boston Approved Building Permits 2009-2022.csv')\n"
     ]
    }
   ],
   "source": [
    "#continue from after making the mega dataset \n",
    "updated_sales_with_permits_by_date = pd.read_csv('output/sales_permitsData_by_date_nullincl.csv')\n",
    "all_permits = pd.read_csv('raw/Boston Approved Building Permits 2009-2022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find rows in permits_df where parcel_id is NOT in sales_df\n",
    "non_matching_permits = all_permits[~all_permits['parcel_id'].isin(updated_sales_with_permits_by_date['parcel_id'])]\n",
    "\n",
    "# Append these rows to the sales_df\n",
    "updated_sales_with_all_permits = pd.concat([updated_sales_with_permits_by_date, non_matching_permits], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_sales_with_all_permits['price'].isnull().sum()\n",
    "updated_sales_with_all_permits.to_csv('/Users/adi/Dropbox (MIT)/6.C35 Group Project/Data/Modified Datasets/Adi/sales__and_permitsData_by_date_all.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dp/6l162bjn4pzdgpn5hkysn1dr0000gn/T/ipykernel_73327/1335179767.py:1: DtypeWarning: Columns (1,4,5,8,12,13,20,21,45,46,47,48,49,50,51,52,53,55,56,62,63,67,68,69,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,91,95,96) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"output/sales__and_permitsData_by_date_all.csv\")\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"output/sales__and_permitsData_by_date_all.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
